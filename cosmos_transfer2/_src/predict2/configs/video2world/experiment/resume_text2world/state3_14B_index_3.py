# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Configs for resuming from stage3 training

import functools
import math

from hydra.core.config_store import ConfigStore

from cosmos_transfer2._src.imaginaire.lazy_config import LazyDict
from cosmos_transfer2._src.predict2.datasets.cached_replay_dataloader import duplicate_batches, duplicate_batches_random
from cosmos_transfer2._src.predict2.models.video2world_model import HighSigmaStrategy

_TRAINER_DEBUG_CONFIG = dict(
    max_iter=25,
    logging_iter=2,
    callbacks=dict(
        every_n_sample_reg=dict(
            every_n=12,
        ),
        every_n_sample_ema=dict(
            every_n=12,
        ),
        reg_model_image2video_sora_val_sampling=dict(
            every_n=13,
            is_debug=True,
            latent_video_length="${model.config.state_t}",
        ),
        ema_model_image2video_sora_val_sampling=dict(
            every_n=13,
            is_debug=True,
            latent_video_length="${model.config.state_t}",
        ),
        reg_model_image2video_vbench_val_sampling=dict(
            every_n=13,
            is_debug=True,
            latent_video_length="${model.config.state_t}",
        ),
        ema_model_image2video_vbench_val_sampling=dict(
            every_n=13,
            is_debug=True,
            latent_video_length="${model.config.state_t}",
        ),
    ),
)
_CKPT_DEBUG_CONFIG = dict(
    save_iter=10,
    load_path="",
    load_training_state=False,
    strict_resume=False,
)


def build_debug_runs(job):
    wo_resume = dict(
        defaults=[
            f"/experiment/{job['job']['name']}",
            "_self_",
        ],
        job=dict(
            group=job["job"]["group"] + "_debug",
            name=f"{job['job']['name']}_WO_RESUME" + "_${now:%Y-%m-%d}_${now:%H-%M-%S}",
        ),
        trainer=_TRAINER_DEBUG_CONFIG,
        checkpoint=_CKPT_DEBUG_CONFIG,
    )

    mock_wo_resume = dict(
        defaults=[
            f"/experiment/{job['job']['name']}",
            {"override /data_train": "mock"},
            "_self_",
        ],
        job=dict(
            group=job["job"]["group"] + "_debug",
            name=f"{job['job']['name']}_MOCK_WO_RESUME" + "_${now:%Y-%m-%d}_${now:%H-%M-%S}",
        ),
        trainer=_TRAINER_DEBUG_CONFIG,
        checkpoint=_CKPT_DEBUG_CONFIG,
    )

    return [wo_resume, mock_wo_resume]


"""
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment=Stage-c_pt_4-Index-3-Size-14B-Res-480-Fps-16-Note-video_data1pt3_augmentor

# diff with resumed config
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment=Stage-a_pt_3-Video2World-Index-5-Size-14B-Res-480-Fps-16-Note-qwen_imagecaption_sync_noise_joint_2framecond
"""
I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR: LazyDict = LazyDict(
    dict(
        defaults=[
            {"override /data_train": "image_cosmos_pretrain_qwen_20250415_video_cosmos_pretrain_v1_3_20250426_s3"},
            {"override /model": "fsdp"},
            {"override /net": "cosmos_v1_14B"},
            {"override /conditioner": "video_prediction_conditioner"},
            {"override /ckpt_type": "dcp"},
            {"override /optimizer": "fusedadamw"},
            {
                "override /callbacks": [
                    "basic",
                    "viz_online_sampling",
                    "wandb",
                    "cluster_speed",
                ]
            },
            {"override /checkpoint": "s3"},
            {"override /tokenizer": "wan2pt1_tokenizer"},
            "_self_",
        ],
        job=dict(
            group="official_runs_video2world",
            name="Stage-c_pt_4-Index-3-Size-14B-Res-480-Fps-16-Note-video_data1pt3_augmentor",
        ),
        optimizer=dict(
            lr=2 ** (-14.5),
            weight_decay=0.2,
        ),
        scheduler=dict(
            f_max=[0.4],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[300_000],
        ),
        model=dict(
            config=dict(
                min_num_conditional_frames=1,  # choose either 1 (img2vid) or 2 (video2world) latent frames
                max_num_conditional_frames=2,
                loss_scale=10.0,
                adjust_video_noise=True,
                scaling="rectified_flow",
                sigma_data=1.0,
                fsdp_shard_size=32,
                resolution="480",
                state_t=20,
                resize_online=True,
                net=dict(
                    rope_enable_fps_modulation=False,
                    rope_h_extrapolation_ratio=2.0,
                    rope_w_extrapolation_ratio=2.0,
                    rope_t_extrapolation_ratio=20.0 / 24,
                ),
                conditioner=dict(
                    use_video_condition=dict(
                        dropout_rate=0.0,
                    ),
                    text=dict(
                        dropout_rate=0.2,
                    ),
                ),
            )
        ),
        checkpoint=dict(
            save_iter=2_500,
            save_to_object_store=dict(
                enabled=True,
            ),
            load_from_object_store=dict(
                enabled=True,
            ),
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-a_pt_3-Video2World-Index-5-Size-14B-Res-480-Fps-16-Note-qwen_imagecaption_sync_noise_joint_2framecond/checkpoints/iter_000052500",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=4,
        ),
        trainer=dict(
            max_iter=150_000,
            logging_iter=200,
            callbacks=dict(
                every_n_sample_reg=dict(
                    every_n=5_000,
                    do_x0_prediction=False,
                    guidance=[0, 3, 7],
                    fps=16,
                ),
                every_n_sample_ema=dict(
                    every_n=5_000,
                    do_x0_prediction=False,
                    guidance=[0, 3, 7],
                    fps=16,
                ),
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=20 // 4,
                        num_workers=6,
                        use_cache=False,
                        cache_size=8,
                        concat_size=1,
                        cache_augment_fn=functools.partial(duplicate_batches, n=1),
                        dataset=dict(
                            resolution="480",
                        ),
                    ),
                    ratio="${trainer.grad_accum_iter}",
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        cache_size=16,
                        concat_size=1,
                        cache_augment_fn=functools.partial(duplicate_batches_random, n=1),
                        dataset=dict(
                            resolution="480",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                        ),
                    ),
                    ratio="${trainer.grad_accum_iter}",
                ),
            ),
        ),
        upload_reproducible_setup=True,
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_6_SIZE_14B_RES_480_SHORT_DURATION_64N: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-6-Size-14B-Res-480-Fps-16-Note-video_data1pt3_short_duration_64n",
        ),
        checkpoint=dict(
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-3-Size-14B-Res-480-Fps-16-Note-video_data1pt3_augmentor/checkpoints/iter_000060000",
            load_training_state=False,
            strict_resume=False,
        ),
        scheduler=dict(
            f_max=[0.2],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=20_000,
            logging_iter=200,
        ),
        dataloader_train=dict(
            dataloaders=dict(
                video_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            augmentor_name="video_basic_augmentor_v3_full_frames",
                        ),
                    ),
                ),
            ),
        ),
    )
)


I2V_STAGE_C_PT_4_INDEX_10_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_CONTINUE_64N: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-10-Size-14B-Res-480-Fps-16-Note-video_data1pt3_continue_64n",
        ),
        checkpoint=dict(
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-3-Size-14B-Res-480-Fps-16-Note-video_data1pt3_augmentor/checkpoints/iter_000060000",
            load_training_state=False,
            strict_resume=False,
        ),
        scheduler=dict(
            f_max=[0.2],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=20_000,
            logging_iter=200,
        ),
    )
)


I2V_STAGE_C_PT_4_INDEX_11_SIZE_14B_RES_480_VIDEO202505_64N: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {"override /data_train": "image_cosmos_pretrain_qwen_20250415_video_cosmos_pretrainvideo_202505_s3"},
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-11-Size-14B-Res-480-Fps-16-Note-video202505_64n",
        ),
        checkpoint=dict(
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-3-Size-14B-Res-480-Fps-16-Note-video_data1pt3_augmentor/checkpoints/iter_000060000",
            load_training_state=False,
            strict_resume=False,
        ),
        scheduler=dict(
            f_max=[0.2],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=20_000,
            logging_iter=200,
        ),
    )
)

"""
# dryrun dataloader
PYTHONPATH=$(pwd) torchrun --nproc_per_node=8 --master_port=12341 projects/cosmos/diffusion/v2/scripts/dataloader_e2e_test_cli.py --niter 5 --dump_vis_data --dump_item --dump_meta --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment=Stage-c_pt_4-Index-20-Size-14B-Res-480-Fps-16-Note-05_20_pretrain2pt2_robo_wan
"""
I2V_STAGE_C_PT_4_INDEX_20_SIZE_14B_RES_480_FPS16_05_20_pretrain2pt2_robo_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrain_v2_2_and_high_quality_v0_robotics_and_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-20-Size-14B-Res-480-Fps-16-Note-05_20_pretrain2pt2_robo_wan",
        ),
        checkpoint=dict(
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-10-Size-14B-Res-480-Fps-16-Note-video_data1pt3_continue_64n/checkpoints/iter_000020000",
            load_training_state=False,
            strict_resume=False,
        ),
        scheduler=dict(
            f_max=[0.4],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=20_000,
            logging_iter=200,
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    )
)

I2V_STAGE_C_PT_4_INDEX_21_SIZE_14B_RES_480p_FPS16_05_22_pretrain2pt2_hq_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrain_v2_2_0522_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-21-Size-14B-Res-480p-Fps-16-Note-05_22_pretrain2pt2_hq_wan",
        ),
        checkpoint=dict(
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-20-Size-14B-Res-480-Fps-16-Note-05_20_pretrain2pt2_robo_wan/checkpoints/iter_000020000",
            load_training_state=True,
            strict_resume=False,
        ),
        model=dict(
            config=dict(
                resolution="480p",
                state_t=20,
                resize_online=True,
                net=dict(
                    sac_config=dict(
                        mode="mm_only",
                    )
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.4],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=200,
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    )
)

"""
# dryrun config
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment=Stage-c_pt_4-Index-22-Size-14B-Res-720-Fps-16-Note-T24_05_22_accumulated_hq_wan
"""
I2V_STAGE_C_PT_4_INDEX_22_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250522_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-22-Size-14B-Res-720-Fps-16-Note-T24_05_22_accumulated_hq_wan",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-21-Size-14B-Res-480p-Fps-16-Note-05_22_pretrain2pt2_hq_wan/checkpoints/iter_000050000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                net=dict(
                    sac_config=dict(
                        mode="predict2_14b_720",
                    )
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.2],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    )
)

I2V_STAGE_C_PT_4_INDEX_23_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan_rerun: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_22_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan['job']['name']}",
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_22_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan["job"]["group"],
            name="Stage-c_pt_4-Index-23-Size-14B-Res-720-Fps-16-Note-T24_05_22_accumulated_hq_wan_rerun",
        ),
        checkpoint=dict(
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-22-Size-14B-Res-720-Fps-16-Note-T24_05_22_accumulated_hq_wan/checkpoints/iter_000008000",
            load_training_state=True,
            strict_resume=False,
        ),
        trainer=dict(
            straggler_detection=dict(
                enabled=False,
                max_diff=1.5,
            )
        ),
    )
)

I2V_STAGE_C_PT_4_INDEX_24_SIZE_14B_RES_720_FPS16_T24_05_27_accumulated_hq_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250527_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-24-Size-14B-Res-720-Fps-16-Note-T24_05_27_accumulated_hq_wan",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-23-Size-14B-Res-720-Fps-16-Note-T24_05_22_accumulated_hq_wan_rerun/checkpoints/iter_000019000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                net=dict(
                    sac_config=dict(
                        mode="predict2_14b_720",
                    )
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.2],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[50_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    )
)

"""
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-25-Size-14B-Res-256-Fps-16-Note-T24_05_27_accumulated_hq_wan_mock_wo_resume" ckpt_type=dummy
"""
I2V_STAGE_C_PT_4_INDEX_25_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250527_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-25-Size-14B-Res-256-Fps-16-Note-T24_05_27_accumulated_hq_wan",
        ),
        checkpoint=dict(
            save_iter=5_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-24-Size-14B-Res-720-Fps-16-Note-T24_05_27_accumulated_hq_wan/checkpoints/iter_000011000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=1,
        ),
        model=dict(
            config=dict(
                resolution="256",
                denoise_replace_gt_frames=False,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=1.0,
                    rope_w_extrapolation_ratio=1.0,
                    rope_t_extrapolation_ratio=1.0,
                    sac_config=dict(
                        mode="mm_only",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[1.0],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[100_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=24,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        cache_size=16,
                        concat_size=1,
                        cache_augment_fn=functools.partial(duplicate_batches_random, n=1.2),
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

"""
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-26-Size-14B-Res-256-Fps-16-Note-T24_05_27_accumulated_hq_wan_rerun_mock_wo_resume" ckpt_type=dummy
"""
I2V_STAGE_C_PT_4_INDEX_26_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan_rerun: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_25_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan['job']['name']}",
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_25_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan["job"]["group"],
            name="Stage-c_pt_4-Index-26-Size-14B-Res-256-Fps-16-Note-T24_05_27_accumulated_hq_wan_rerun",
        ),
        model=dict(
            config=dict(
                denoise_replace_gt_frames=True,
            )
        ),
        checkpoint=dict(
            save_iter=2_500,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-25-Size-14B-Res-256-Fps-16-Note-T24_05_27_accumulated_hq_wan_64N/checkpoints/iter_000005000",
            load_training_state=True,
            strict_resume=False,
        ),
    )
)

"""
# print config
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-27-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan"

torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-27-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan_mock_wo_resume" ckpt_type=dummy
"""
I2V_STAGE_C_PT_4_INDEX_27_SIZE_14B_RES_480p_FPS16_T24_05_28_accumulated_hq_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250528_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-27-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan",
        ),
        checkpoint=dict(
            save_iter=2_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-26-Size-14B-Res-256-Fps-16-Note-T24_05_27_accumulated_hq_wan_rerun/checkpoints/iter_000047500",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=4,
        ),
        model=dict(
            config=dict(
                resolution="480p",
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=2.0,
                    rope_w_extrapolation_ratio=2.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="mm_only",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.4],  # tune it on the fly. 1.0 is too agressive. loss is not stable.
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=6,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_28_SIZE_14B_RES_480p_FPS16_T24_05_28_accumulated_hq_wan_tune_pmean_from_index27_24k: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250528_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-28-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan_tune_pmean_from_index27_24k",
        ),
        checkpoint=dict(
            save_iter=2_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-27-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan/checkpoints/iter_000024000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=4,
        ),
        model=dict(
            config=dict(
                resolution="480p",
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=0.7,
                    p_std=1.0,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=2.0,
                    rope_w_extrapolation_ratio=2.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="mm_only",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.4],  # tune it on the fly. 1.0 is too agressive. loss is not stable.
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=6,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_29_SIZE_14B_RES_480p_FPS16_T24_06_01_accumulated_hq_wan: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250601_dedup_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-29-Size-14B-Res-480p-Fps-16-Note-T24_06_01_accumulated_hq_wan",
        ),
        checkpoint=dict(
            save_iter=2_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-28-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan_tune_pmean_from_index27_24k/checkpoints/iter_000038000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=4,
        ),
        model=dict(
            config=dict(
                resolution="480p",
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=0.0,
                    p_std=1.0,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=2.0,
                    rope_w_extrapolation_ratio=2.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="mm_only",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.4],  # tune it on the fly. 1.0 is too agressive. loss is not stable.
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=6,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_30_SIZE_14B_RES_480p_FPS16_T24_HQ_V0: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-30-Size-14B-Res-480p-Fps-16-Note-T24_HQ_V0_FROM_28",
        ),
        checkpoint=dict(
            save_iter=2_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-28-Size-14B-Res-480p-Fps-16-Note-T24_05_28_accumulated_hq_wan_tune_pmean_from_index27_24k/checkpoints/iter_000038000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=4,
        ),
        model=dict(
            config=dict(
                resolution="480p",
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=0.0,
                    p_std=1.0,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=2.0,
                    rope_w_extrapolation_ratio=2.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="mm_only",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.4],  # tune it on the fly. 1.0 is too agressive. loss is not stable.
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=6,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_31_SIZE_14B_RES_720p_FPS16_T24_HQ_V0: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-31-Size-14B-Res-720p-Fps-16-Note-T24_HQ_V0_FROM_30",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-30-Size-14B-Res-480p-Fps-16-Note-T24_HQ_V0_FROM_28/checkpoints/iter_000008000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=0.0,
                    p_std=1.0,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_32_SIZE_14B_RES_480p_FPS16_T24_06_02_data_from_29: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250602_dedup_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-32-Size-14B-Res-480p-Fps-16-Note-T24_06_02_data_from_29",
        ),
        checkpoint=dict(
            save_iter=2_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-29-Size-14B-Res-480p-Fps-16-Note-T24_06_01_accumulated_hq_wan",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=0.0,
                    p_std=1.0,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_33_SIZE_14B_RES_720_FPS16_T24_06_02_data_tune_sigma_extrahigh_from_32: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250602_dedup_accumulated_and_high_quality_v1_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-33-Size-14B-Res-720-Fps-16-Note-T24_06_02_data_tune_sigma_extrahigh_from_32",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-32-Size-14B-Res-480p-Fps-16-Note-T24_06_02_data_from_29",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.UNIFORM80_2000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=1.0,
                    p_std=1.0,
                    sigma_max=1000,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_34_SIZE_14B_RES_720p_FPS16_T24_HQ_V0_FROM_31: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-34-Size-14B-Res-720p-Fps-16-Note-T24_HQ_V0_FROM_31",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-31-Size-14B-Res-720p-Fps-16-Note-T24_HQ_V0_FROM_30",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                denoise_replace_gt_frames=True,
                high_sigma_strategy=str(HighSigmaStrategy.UNIFORM80_2000),
                high_sigma_ratio=0.05,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=0.0,
                    p_std=1.0,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

"""
# run local debug
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-35-Size-14B-Res-720-Fps-16-Note-T24_06_04_data_tune_sigma_from_33_mock_wo_resume" ckpt_type=dummy model.config.net.num_blocks=2
"""
I2V_STAGE_C_PT_4_INDEX_35_SIZE_14B_RES_720_FPS16_T24_06_04_data_tune_sigma_from_33: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250604_dedup_accumulated_and_high_quality_v2_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-35-Size-14B-Res-720-Fps-16-Note-T24_06_04_data_tune_sigma_from_33",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-33-Size-14B-Res-720-Fps-16-Note-T24_06_02_data_tune_sigma_extrahigh_from_32",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.08,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=1.0,
                    p_std=1.5,
                    sigma_max=500,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_36_SIZE_14B_RES_720_FPS16_T24_06_04_data_tune_sigma_from_33: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250604_dedup_accumulated_and_high_quality_v2_wan_synthetic_v0_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-36-Size-14B-Res-720-Fps-16-Note-T24_06_04_data_tune_sigma_from_33",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-33-Size-14B-Res-720-Fps-16-Note-T24_06_02_data_tune_sigma_extrahigh_from_32/checkpoints/iter_000010000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.20],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_37_SIZE_14B_RES_720_FPS16_T24_HQV2_from_35: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v2_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-37-Size-14B-Res-720-Fps-16-Note-T24_HQV2_from_35",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-35-Size-14B-Res-720-Fps-16-Note-T24_06_04_data_tune_sigma_from_33/checkpoints/iter_000024000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

"""
# local debug
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-38-Size-14B-Res-720-Fps-16-Note-T24_HQV3_from_35_mock_wo_resume" ckpt_type=dummy model.config.net.num_blocks=2
"""
I2V_STAGE_C_PT_4_INDEX_38_SIZE_14B_RES_720_FPS16_T24_HQV3_from_35: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v3_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-38-Size-14B-Res-720-Fps-16-Note-T24_HQV3_from_35",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-35-Size-14B-Res-720-Fps-16-Note-T24_06_04_data_tune_sigma_from_33/checkpoints/iter_000024000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_39_SIZE_14B_RES_720_FPS16_T24_HQV2pt1_from_37: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v2_1_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-39-Size-14B-Res-720-Fps-16-Note-T24_HQV2pt1_from_37",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-37-Size-14B-Res-720-Fps-16-Note-T24_HQV2_from_35",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


"""
# local debug
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38_mock_wo_resume" ckpt_type=dummy model.config.net.num_blocks=2
"""
I2V_STAGE_C_PT_4_INDEX_40_SIZE_14B_RES_720_FPS16_T24_HQV3pt1_from_38: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v3_1_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-38-Size-14B-Res-720-Fps-16-Note-T24_HQV3_from_35",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[40_000],
        ),
        trainer=dict(
            max_iter=100_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_41_SIZE_14B_RES_720_FPS16_T24_HQV3pt1_1080_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v3_1_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-41-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_1080_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt1080p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_42_SIZE_14B_RES_720_FPS16_T24_HQV4_1080_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v4_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-42-Size-14B-Res-720-Fps-16-Note-T24_HQV4_1080_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt1080p",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


"""
# print config
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment=Stage-c_pt_4-Index-43-Size-14B-Res-720-Fps-16-Note-T24_HQV5_from_40
"""
I2V_STAGE_C_PT_4_INDEX_43_SIZE_14B_RES_720_FPS16_T24_HQV5_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-43-Size-14B-Res-720-Fps-16-Note-T24_HQV5_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_44_SIZE_14B_RES_720_FPS16_T24_HQV6_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v6_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-44-Size-14B-Res-720-Fps-16-Note-T24_HQV6_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

"""
# print config
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-45-Size-14B-Res-720-Fps-16-Note-T24_HQV2_1_from_35"
# dryrun dataloader
PYTHONPATH=$(pwd) torchrun --nproc_per_node=8 --master_port=12341 projects/cosmos/diffusion/v2/scripts/dataloader_e2e_test_cli.py --niter 5 --dump_vis_data --dump_item --dump_meta --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment=Stage-c_pt_4-Index-45-Size-14B-Res-720-Fps-16-Note-T24_HQV2_1_from_35
"""
I2V_STAGE_C_PT_4_INDEX_45_SIZE_14B_RES_720_FPS16_T24_HQV2_1_from_35: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v2_1_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-45-Size-14B-Res-720-Fps-16-Note-T24_HQV2_1_from_35",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-37-Size-14B-Res-720-Fps-16-Note-T24_HQV2_from_35",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[30_001],
        ),
        trainer=dict(
            max_iter=30_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                            use_native_fps=True,
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_46_SIZE_14B_RES_720_FPS16_T24_HQV2_1_from_35: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v2_1_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-46-Size-14B-Res-720-Fps-16-Note-T24_HQV2_1_from_35",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-37-Size-14B-Res-720-Fps-16-Note-T24_HQV2_from_35",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[30_001],
        ),
        trainer=dict(
            max_iter=30_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                            use_native_fps=True,
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_47_SIZE_14B_RES_720_FPS16_T24_HQV5_FIX_DATA_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-47-Size-14B-Res-720-Fps-16-Note-T24_HQV5_FIX_DATA_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[25_001],
        ),
        trainer=dict(
            max_iter=25_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                            use_native_fps=True,
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_48_SIZE_14B_RES_720_FPS16_T24_HQV5_VIDOE_ONLY_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-48-Size-14B-Res-720-Fps-16-Note-T24_HQV5_VIDOE_ONLY_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=0,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_49_SIZE_14B_RES_720_FPS16_T24_HQV5_ROPE_TUNE_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-49-Size-14B-Res-720-Fps-16-Note-T24_HQV5_ROPE_TUNE_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=1.0,
                    rope_w_extrapolation_ratio=1.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=20_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


"""
# print
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-50-Size-14B-Res-720-Fps-16-Note-T24_HQV5_SHIFT24_from_40"

local train 14B with shift24
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-50-Size-14B-Res-720-Fps-16-Note-T24_HQV5_SHIFT24_from_40_mock_wo_resume" model.config.net.num_blocks=10
"""
I2V_STAGE_C_PT_4_INDEX_50_SIZE_14B_RES_720_FPS16_T24_HQV5_SHIFT24_from_40: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-50-Size-14B-Res-720-Fps-16-Note-T24_HQV5_SHIFT24_from_40",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-40-Size-14B-Res-720-Fps-16-Note-T24_HQV3pt1_from_38/checkpoints/iter_000015000",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.SHIFT24),
                high_sigma_ratio=0.02,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=20_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


"""
test locally
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-51-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_43_mock_wo_resume" model.config.net.num_blocks=10
"""
I2V_STAGE_C_PT_4_INDEX_51_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_43: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250612_dedup_accumulated_and_high_quality_v3_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-51-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_43",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-43-Size-14B-Res-720-Fps-16-Note-T24_HQV5_from_40",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.5,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[50_001],
        ),
        trainer=dict(
            max_iter=50_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=3,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


"""
# local run it
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-52-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_51_mock_wo_resume" model.config.net.num_blocks=10
"""
I2V_STAGE_C_PT_4_INDEX_52_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_51: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250612_dedup_accumulated_and_high_quality_v3_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-52-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_51",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-51-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_43",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.BALANCED_TWO_HEADS_V1),
                high_sigma_ratio=0.05,
                low_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.6,
                    sigma_max=120,
                    sigma_min=0.2,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[70_001],
        ),
        trainer=dict(
            max_iter=70_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=3,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

"""
# print config
torchrun --nproc_per_node=1 --master_port=12341 -m scripts.train --dryrun --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-53-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_HARDCODED_20STEPS_from_51"

# local run it
torchrun --nproc_per_node=4 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="Stage-c_pt_4-Index-53-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_HARDCODED_20STEPS_from_51_mock_wo_resume" model.config.net.num_blocks=10 model_parallel.context_parallel_size=4 ckpt_type=dummy
"""
I2V_STAGE_C_PT_4_INDEX_53_SIZE_14B_RES_720_FPS16_T24_DATA_0612_HARDCODED_20STEPS_from_51: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250612_dedup_accumulated_and_high_quality_v3_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-53-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_HARDCODED_20STEPS_from_51",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-51-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_43",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.HARDCODED_20steps),
                high_sigma_ratio=0.05,
                low_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.6,
                    sigma_max=120,
                    sigma_min=0.2,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[70_001],
        ),
        trainer=dict(
            max_iter=70_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
            callbacks=dict(
                every_n_sample_ema=dict(
                    num_sampling_step=20,
                ),
                every_n_sample_reg=dict(
                    num_sampling_step=20,
                ),
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=3,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_54_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_52: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_pretrainvideo_20250612_dedup_accumulated_and_high_quality_v3_202505_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-54-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_52",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-52-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_51",
            load_training_state=True,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.BALANCED_TWO_HEADS_V1),
                high_sigma_ratio=0.05,
                low_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.6,
                    sigma_max=120,
                    sigma_min=0.2,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.3],
            f_min=[0.01],
            warm_up_steps=[2_000],
            cycle_lengths=[150_001],
        ),
        trainer=dict(
            max_iter=150_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=3,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_55_SIZE_14B_RES_720_FPS16_T24_DATA_HQ_V5_from_54: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-55-Size-14B-Res-720-Fps-16-Note-T24_DATA_HQ_V5_from_54",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-54-Size-14B-Res-720-Fps-16-Note-T24_DATA_0612_from_52",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.BALANCED_TWO_HEADS_V1),
                high_sigma_ratio=0.05,
                low_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.6,
                    sigma_max=120,
                    sigma_min=0.2,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.3],
            f_min=[0.01],
            warm_up_steps=[1_000],
            cycle_lengths=[30_001],
        ),
        trainer=dict(
            max_iter=30_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="gt720p",
                        ),
                    ),
                    ratio=3,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)


"""
torchrun --nproc_per_node=8 --master_port=12341 -m scripts.train --config=projects/cosmos/diffusion/v2/configs/video2world/config.py -- experiment="I2V_STAGE_C_PT_4_INDEX_00_SIZE_14B_RES_480_FPS16_PROFILING"
"""
I2V_STAGE_C_PT_4_INDEX_00_SIZE_14B_RES_480_FPS16_PROFILING: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "mock",
            },
            {"override /ckpt_type": "dummy"},
            {
                "override /callbacks": [
                    "basic",
                    "wandb",
                    "cluster_speed",
                ]
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="I2V_STAGE_C_PT_4_INDEX_00_SIZE_14B_RES_480_FPS16_PROFILING",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="",
        ),
        trainer=dict(
            max_iter=2_00,
            logging_iter=20,
        ),
        model_parallel=dict(
            context_parallel_size=4,
        ),
        model=dict(
            config=dict(
                state_t=20,  # 24
                fsdp_shard_size=32,
                resolution="480",
            )
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=5,
                        dataset=dict(
                            t5_dim=1024,
                            resolution="${model.config.resolution}",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        dataset=dict(
                            t5_dim=1024,
                            resolution="${model.config.resolution}",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
        upload_reproducible_setup=True,
    ),
    flags={"allow_objects": True},
)


I2V_STAGE_C_PT_4_INDEX_100_SIZE_14B_RES_720_FPS10_T15_HQV5_from_43: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },  # @qinsheng
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-100-Size-14B-Res-720-Fps-10-Note-T15_HQV5_from_43",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-43-Size-14B-Res-720-Fps-16-Note-T24_HQV5_from_40/checkpoints/iter_000018000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="720",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=16,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=16.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=61,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)

I2V_STAGE_C_PT_4_INDEX_101_SIZE_14B_RES_480_FPS10_T15_HQV5_from_43: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-101-Size-14B-Res-480-Fps-10-Note-T15_HQV5_from_43",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-43-Size-14B-Res-720-Fps-16-Note-T24_HQV5_from_40/checkpoints/iter_000018000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="480",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=16,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=16.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=61,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)
I2V_STAGE_C_PT_4_INDEX_102_SIZE_14B_RES_480_FPS16_T24_HQV5_from_43: LazyDict = LazyDict(
    dict(
        defaults=[
            f"/experiment/{I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR['job']['name']}",
            {
                "override /data_train": "image_cosmos_pretrain_and_synthetic_20250520_video_cosmos_posttraining_hq_v5_20250607_s3"
            },
            "_self_",
        ],
        job=dict(
            group=I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR["job"]["group"],
            name="Stage-c_pt_4-Index-102-Size-14B-Res-480-Fps-16-Note-T24_HQV5_from_43",
        ),
        checkpoint=dict(
            save_iter=1_000,
            load_path="cosmos_diffusion_v2/official_runs_vid2vid/Stage-c_pt_4-Index-43-Size-14B-Res-720-Fps-16-Note-T24_HQV5_from_40/checkpoints/iter_000018000",
            load_training_state=False,
            strict_resume=False,
        ),
        model_parallel=dict(
            context_parallel_size=8,
        ),
        model=dict(
            config=dict(
                resolution="480",
                high_sigma_strategy=str(HighSigmaStrategy.LOGUNIFORM200_100000),
                high_sigma_ratio=0.05,
                denoise_replace_gt_frames=True,
                state_t=24,
                resize_online=True,
                tokenizer=dict(
                    temporal_window=16,
                ),
                sde=dict(
                    p_mean=math.log(4.0),
                    p_std=1.2,
                    sigma_max=200,
                    sigma_min=0.01,
                ),
                net=dict(
                    rope_h_extrapolation_ratio=3.0,
                    rope_w_extrapolation_ratio=3.0,
                    rope_t_extrapolation_ratio=24.0 / 24,
                    sac_config=dict(
                        mode="predict2_14b_720",
                    ),
                ),
            ),
        ),
        scheduler=dict(
            f_max=[0.25],
            f_min=[0.1],
            warm_up_steps=[2_000],
            cycle_lengths=[20_001],
        ),
        trainer=dict(
            max_iter=18_000,
            logging_iter=100,
            straggler_detection=dict(
                enabled=True,
                max_diff=1.5,
            ),
        ),
        dataloader_train=dict(
            dataloaders=dict(
                image_data=dict(
                    dataloader=dict(
                        batch_size=3,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            dataset_resolution_type="gt720p",
                            caption_type="qwen2p5_7b_v4",
                            embedding_type="t5_xxl",
                        ),
                    ),
                    ratio=1,
                ),
                video_data=dict(
                    dataloader=dict(
                        batch_size=1,
                        use_cache=False,
                        dataset=dict(
                            resolution="${model.config.resolution}",
                            video_decoder_name="video_naive_bytes",
                            augmentor_name="video_basic_augmentor_v2",
                            embedding_type="t5_xxl",
                            max_fps_thres=60,
                            min_fps_thres=10,
                            caption_type="t2w_qwen2p5_7b",
                            num_video_frames=93,
                            dataset_resolution_type="all",
                        ),
                    ),
                    ratio=1,
                ),
            ),
        ),
    ),
    flags={"allow_objects": True},
)
cs = ConfigStore.instance()
cs.store(
    group="experiment",
    package="_global_",
    name=f"{I2V_STAGE_C_PT_4_INDEX_00_SIZE_14B_RES_480_FPS16_PROFILING['job']['name']}",
    node=I2V_STAGE_C_PT_4_INDEX_00_SIZE_14B_RES_480_FPS16_PROFILING,
)

for _item, _item_wo_resume, _item_mock_wo_resume in [
    [
        I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_3_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_AUGMENTOR),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_6_SIZE_14B_RES_480_SHORT_DURATION_64N,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_6_SIZE_14B_RES_480_SHORT_DURATION_64N),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_10_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_CONTINUE_64N,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_10_SIZE_14B_RES_480_NEW_VIDEO_DATA1PT3_CONTINUE_64N),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_11_SIZE_14B_RES_480_VIDEO202505_64N,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_11_SIZE_14B_RES_480_VIDEO202505_64N),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_20_SIZE_14B_RES_480_FPS16_05_20_pretrain2pt2_robo_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_20_SIZE_14B_RES_480_FPS16_05_20_pretrain2pt2_robo_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_21_SIZE_14B_RES_480p_FPS16_05_22_pretrain2pt2_hq_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_21_SIZE_14B_RES_480p_FPS16_05_22_pretrain2pt2_hq_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_22_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_22_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_23_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan_rerun,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_23_SIZE_14B_RES_720_FPS16_T24_05_22_accumulated_hq_wan_rerun),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_24_SIZE_14B_RES_720_FPS16_T24_05_27_accumulated_hq_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_24_SIZE_14B_RES_720_FPS16_T24_05_27_accumulated_hq_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_25_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_25_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_26_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan_rerun,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_26_SIZE_14B_RES_256_FPS16_T24_05_27_accumulated_hq_wan_rerun),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_27_SIZE_14B_RES_480p_FPS16_T24_05_28_accumulated_hq_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_27_SIZE_14B_RES_480p_FPS16_T24_05_28_accumulated_hq_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_28_SIZE_14B_RES_480p_FPS16_T24_05_28_accumulated_hq_wan_tune_pmean_from_index27_24k,
        *build_debug_runs(
            I2V_STAGE_C_PT_4_INDEX_28_SIZE_14B_RES_480p_FPS16_T24_05_28_accumulated_hq_wan_tune_pmean_from_index27_24k
        ),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_29_SIZE_14B_RES_480p_FPS16_T24_06_01_accumulated_hq_wan,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_29_SIZE_14B_RES_480p_FPS16_T24_06_01_accumulated_hq_wan),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_30_SIZE_14B_RES_480p_FPS16_T24_HQ_V0,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_30_SIZE_14B_RES_480p_FPS16_T24_HQ_V0),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_31_SIZE_14B_RES_720p_FPS16_T24_HQ_V0,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_31_SIZE_14B_RES_720p_FPS16_T24_HQ_V0),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_32_SIZE_14B_RES_480p_FPS16_T24_06_02_data_from_29,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_32_SIZE_14B_RES_480p_FPS16_T24_06_02_data_from_29),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_33_SIZE_14B_RES_720_FPS16_T24_06_02_data_tune_sigma_extrahigh_from_32,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_33_SIZE_14B_RES_720_FPS16_T24_06_02_data_tune_sigma_extrahigh_from_32),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_34_SIZE_14B_RES_720p_FPS16_T24_HQ_V0_FROM_31,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_34_SIZE_14B_RES_720p_FPS16_T24_HQ_V0_FROM_31),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_35_SIZE_14B_RES_720_FPS16_T24_06_04_data_tune_sigma_from_33,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_35_SIZE_14B_RES_720_FPS16_T24_06_04_data_tune_sigma_from_33),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_36_SIZE_14B_RES_720_FPS16_T24_06_04_data_tune_sigma_from_33,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_36_SIZE_14B_RES_720_FPS16_T24_06_04_data_tune_sigma_from_33),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_37_SIZE_14B_RES_720_FPS16_T24_HQV2_from_35,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_37_SIZE_14B_RES_720_FPS16_T24_HQV2_from_35),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_38_SIZE_14B_RES_720_FPS16_T24_HQV3_from_35,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_38_SIZE_14B_RES_720_FPS16_T24_HQV3_from_35),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_39_SIZE_14B_RES_720_FPS16_T24_HQV2pt1_from_37,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_39_SIZE_14B_RES_720_FPS16_T24_HQV2pt1_from_37),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_40_SIZE_14B_RES_720_FPS16_T24_HQV3pt1_from_38,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_40_SIZE_14B_RES_720_FPS16_T24_HQV3pt1_from_38),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_41_SIZE_14B_RES_720_FPS16_T24_HQV3pt1_1080_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_41_SIZE_14B_RES_720_FPS16_T24_HQV3pt1_1080_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_42_SIZE_14B_RES_720_FPS16_T24_HQV4_1080_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_42_SIZE_14B_RES_720_FPS16_T24_HQV4_1080_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_43_SIZE_14B_RES_720_FPS16_T24_HQV5_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_43_SIZE_14B_RES_720_FPS16_T24_HQV5_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_44_SIZE_14B_RES_720_FPS16_T24_HQV6_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_44_SIZE_14B_RES_720_FPS16_T24_HQV6_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_45_SIZE_14B_RES_720_FPS16_T24_HQV2_1_from_35,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_45_SIZE_14B_RES_720_FPS16_T24_HQV2_1_from_35),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_46_SIZE_14B_RES_720_FPS16_T24_HQV2_1_from_35,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_46_SIZE_14B_RES_720_FPS16_T24_HQV2_1_from_35),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_47_SIZE_14B_RES_720_FPS16_T24_HQV5_FIX_DATA_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_47_SIZE_14B_RES_720_FPS16_T24_HQV5_FIX_DATA_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_48_SIZE_14B_RES_720_FPS16_T24_HQV5_VIDOE_ONLY_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_48_SIZE_14B_RES_720_FPS16_T24_HQV5_VIDOE_ONLY_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_49_SIZE_14B_RES_720_FPS16_T24_HQV5_ROPE_TUNE_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_49_SIZE_14B_RES_720_FPS16_T24_HQV5_ROPE_TUNE_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_50_SIZE_14B_RES_720_FPS16_T24_HQV5_SHIFT24_from_40,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_50_SIZE_14B_RES_720_FPS16_T24_HQV5_SHIFT24_from_40),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_51_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_43,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_51_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_43),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_52_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_51,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_52_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_51),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_53_SIZE_14B_RES_720_FPS16_T24_DATA_0612_HARDCODED_20STEPS_from_51,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_53_SIZE_14B_RES_720_FPS16_T24_DATA_0612_HARDCODED_20STEPS_from_51),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_54_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_52,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_54_SIZE_14B_RES_720_FPS16_T24_DATA_0612_from_52),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_55_SIZE_14B_RES_720_FPS16_T24_DATA_HQ_V5_from_54,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_55_SIZE_14B_RES_720_FPS16_T24_DATA_HQ_V5_from_54),
    ],
    # variants
    [
        I2V_STAGE_C_PT_4_INDEX_100_SIZE_14B_RES_720_FPS10_T15_HQV5_from_43,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_100_SIZE_14B_RES_720_FPS10_T15_HQV5_from_43),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_101_SIZE_14B_RES_480_FPS10_T15_HQV5_from_43,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_101_SIZE_14B_RES_480_FPS10_T15_HQV5_from_43),
    ],
    [
        I2V_STAGE_C_PT_4_INDEX_102_SIZE_14B_RES_480_FPS16_T24_HQV5_from_43,
        *build_debug_runs(I2V_STAGE_C_PT_4_INDEX_102_SIZE_14B_RES_480_FPS16_T24_HQV5_from_43),
    ],
]:
    cs.store(group="experiment", package="_global_", name=f"{_item['job']['name']}", node=_item)
    if _item_wo_resume is not None:
        cs.store(
            group="experiment",
            package="_global_",
            name=f"{_item['job']['name']}_wo_resume",
            node=_item_wo_resume,
        )
    if _item_mock_wo_resume is not None:
        cs.store(
            group="experiment",
            package="_global_",
            name=f"{_item['job']['name']}_mock_wo_resume",
            node=_item_mock_wo_resume,
        )
